{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrangling and Cleaning WeRateDogs Twitter Archive\n",
    "=================================================\n",
    "\n",
    "# Introduction\n",
    "\n",
    "This dataset comes from an archive of tweets from the Twitter user @dog_rates, also known as WeRateDogs. This account rates people's dogs along with a humorous comment about the dog. The dog then gets a rating that almost always has a denominator of 10. The numerators on the other hand, almost always go beyond 10, [because they're good dogs Brent](https://knowyourmeme.com/memes/theyre-good-dogs-brent). The account has over 7 million followers as of 2018. In this notebook, I will wrangle, clean, and analyze the twitter archive and other supporting data.\n",
    "\n",
    "### The Process\n",
    "\n",
    "The data for this project requires gathering from a few different sources. The twitter archive, `df_twitter`, comes from a file given to Udacity by WeRateDogs. The other file, `image_predictions` comes from Udacity's servers and will be downloaded by utilizing the `requests` library. All other data will be gathered by accessing the Twitter API and extracting the JSON of each tweet. I will then use the extracted JSON to add extra data to `df_twitter`. I also use the `BeautifulSoup` library to extract users that were tagged in the photos of the tweet. Once I gather all the data I need, I will clean and visualize it.\n",
    "\n",
    "### Twitter Archive\n",
    "\n",
    "The archive was downloaded using [this link](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958_twitter-archive-enhanced/twitter-archive-enhanced.csv). In the table there are a total of 17 columns. Most of these columns are described on the [twitter developer web page](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object.html) on tweet objects. \n",
    "\n",
    "### Image Predictions\n",
    "\n",
    "This file was downloaded using [this link](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv) and the `requests` library to save the file for analysis. The column descriptions are as follows:\n",
    "\n",
    "* tweet_id is the last part of the tweet URL after \"status/\" → https://twitter.com/dog_rates/status/889531135344209921\n",
    "* p1 is the algorithm's #1 prediction for the image in the tweet → golden retriever\n",
    "* p1_conf is how confident the algorithm is in its #1 prediction → 95%\n",
    "* p1_dog is whether or not the #1 prediction is a breed of dog → TRUE\n",
    "* p2 is the algorithm's second most likely prediction → Labrador retriever\n",
    "* p2_conf is how confident the algorithm is in its #2 prediction → 1%\n",
    "* p2_dog is whether or not the #2 prediction is a breed of dog → TRUE\n",
    "* etc.\n",
    "\n",
    "# Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import time\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image-predictions.tsv with requests library\n",
    "r = requests.get('https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('image-predictions.tsv', 'wb') as file:\n",
    "    file.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions = pd.read_csv('image-predictions.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>666020888022790149</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Welsh_springer_spaniel</td>\n",
       "      <td>0.465074</td>\n",
       "      <td>True</td>\n",
       "      <td>collie</td>\n",
       "      <td>0.156665</td>\n",
       "      <td>True</td>\n",
       "      <td>Shetland_sheepdog</td>\n",
       "      <td>0.061428</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>666029285002620928</td>\n",
       "      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.506826</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.074192</td>\n",
       "      <td>True</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.072010</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>666033412701032449</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>German_shepherd</td>\n",
       "      <td>0.596461</td>\n",
       "      <td>True</td>\n",
       "      <td>malinois</td>\n",
       "      <td>0.138584</td>\n",
       "      <td>True</td>\n",
       "      <td>bloodhound</td>\n",
       "      <td>0.116197</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>666044226329800704</td>\n",
       "      <td>https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.408143</td>\n",
       "      <td>True</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.360687</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.222752</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>666049248165822465</td>\n",
       "      <td>https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.560311</td>\n",
       "      <td>True</td>\n",
       "      <td>Rottweiler</td>\n",
       "      <td>0.243682</td>\n",
       "      <td>True</td>\n",
       "      <td>Doberman</td>\n",
       "      <td>0.154629</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                          jpg_url  \\\n",
       "0  666020888022790149  https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg   \n",
       "1  666029285002620928  https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg   \n",
       "2  666033412701032449  https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg   \n",
       "3  666044226329800704  https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg   \n",
       "4  666049248165822465  https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg   \n",
       "\n",
       "   img_num                      p1   p1_conf  p1_dog                  p2  \\\n",
       "0        1  Welsh_springer_spaniel  0.465074    True              collie   \n",
       "1        1                 redbone  0.506826    True  miniature_pinscher   \n",
       "2        1         German_shepherd  0.596461    True            malinois   \n",
       "3        1     Rhodesian_ridgeback  0.408143    True             redbone   \n",
       "4        1      miniature_pinscher  0.560311    True          Rottweiler   \n",
       "\n",
       "    p2_conf  p2_dog                   p3   p3_conf  p3_dog  \n",
       "0  0.156665    True    Shetland_sheepdog  0.061428    True  \n",
       "1  0.074192    True  Rhodesian_ridgeback  0.072010    True  \n",
       "2  0.138584    True           bloodhound  0.116197    True  \n",
       "3  0.360687    True   miniature_pinscher  0.222752    True  \n",
       "4  0.243682    True             Doberman  0.154629    True  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2075 entries, 0 to 2074\n",
      "Data columns (total 12 columns):\n",
      "tweet_id    2075 non-null int64\n",
      "jpg_url     2075 non-null object\n",
      "img_num     2075 non-null int64\n",
      "p1          2075 non-null object\n",
      "p1_conf     2075 non-null float64\n",
      "p1_dog      2075 non-null bool\n",
      "p2          2075 non-null object\n",
      "p2_conf     2075 non-null float64\n",
      "p2_dog      2075 non-null bool\n",
      "p3          2075 non-null object\n",
      "p3_conf     2075 non-null float64\n",
      "p3_dog      2075 non-null bool\n",
      "dtypes: bool(3), float64(3), int64(2), object(4)\n",
      "memory usage: 152.1+ KB\n"
     ]
    }
   ],
   "source": [
    "image_predictions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `image_predictions` file is pretty tidy. From only looking at the first five rows, I can already see that I will probably only need the `tweet_id`, `jpg_url`, `p1`, and `p1_conf` columns of the rows that contain `True` in `p1_dog`. The other columns have a very low confidence percentage and will not be necessary to add to the data. Next lets look at the twitter archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 16:23:56 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892420643...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Phineas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 00:17:27 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Tilly. She's just checking pup on you....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892177421...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Tilly</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>891815181378084864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-31 00:18:03 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891815181...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Archie</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>891689557279858688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-30 15:58:51 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Darla. She commenced a snooze mid meal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891689557...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Darla</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>891327558926688256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-29 16:00:24 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Franklin. He would like you to stop ca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891327558...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "0  892420643555336193                    NaN                  NaN   \n",
       "1  892177421306343426                    NaN                  NaN   \n",
       "2  891815181378084864                    NaN                  NaN   \n",
       "3  891689557279858688                    NaN                  NaN   \n",
       "4  891327558926688256                    NaN                  NaN   \n",
       "\n",
       "                   timestamp  \\\n",
       "0  2017-08-01 16:23:56 +0000   \n",
       "1  2017-08-01 00:17:27 +0000   \n",
       "2  2017-07-31 00:18:03 +0000   \n",
       "3  2017-07-30 15:58:51 +0000   \n",
       "4  2017-07-29 16:00:24 +0000   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text  retweeted_status_id  \\\n",
       "0  This is Phineas. He's a mystical boy. Only eve...                  NaN   \n",
       "1  This is Tilly. She's just checking pup on you....                  NaN   \n",
       "2  This is Archie. He is a rare Norwegian Pouncin...                  NaN   \n",
       "3  This is Darla. She commenced a snooze mid meal...                  NaN   \n",
       "4  This is Franklin. He would like you to stop ca...                  NaN   \n",
       "\n",
       "   retweeted_status_user_id retweeted_status_timestamp  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "2                       NaN                        NaN   \n",
       "3                       NaN                        NaN   \n",
       "4                       NaN                        NaN   \n",
       "\n",
       "                                       expanded_urls  rating_numerator  \\\n",
       "0  https://twitter.com/dog_rates/status/892420643...                13   \n",
       "1  https://twitter.com/dog_rates/status/892177421...                13   \n",
       "2  https://twitter.com/dog_rates/status/891815181...                12   \n",
       "3  https://twitter.com/dog_rates/status/891689557...                13   \n",
       "4  https://twitter.com/dog_rates/status/891327558...                12   \n",
       "\n",
       "   rating_denominator      name doggo floofer pupper puppo  \n",
       "0                  10   Phineas  None    None   None  None  \n",
       "1                  10     Tilly  None    None   None  None  \n",
       "2                  10    Archie  None    None   None  None  \n",
       "3                  10     Darla  None    None   None  None  \n",
       "4                  10  Franklin  None    None   None  None  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 17 columns):\n",
      "tweet_id                      2356 non-null int64\n",
      "in_reply_to_status_id         78 non-null float64\n",
      "in_reply_to_user_id           78 non-null float64\n",
      "timestamp                     2356 non-null object\n",
      "source                        2356 non-null object\n",
      "text                          2356 non-null object\n",
      "retweeted_status_id           181 non-null float64\n",
      "retweeted_status_user_id      181 non-null float64\n",
      "retweeted_status_timestamp    181 non-null object\n",
      "expanded_urls                 2297 non-null object\n",
      "rating_numerator              2356 non-null int64\n",
      "rating_denominator            2356 non-null int64\n",
      "name                          2356 non-null object\n",
      "doggo                         2356 non-null object\n",
      "floofer                       2356 non-null object\n",
      "pupper                        2356 non-null object\n",
      "puppo                         2356 non-null object\n",
      "dtypes: float64(4), int64(3), object(10)\n",
      "memory usage: 313.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_twitter.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_twitter` is pretty messy. Just by taking a glance at the first five rows, we can already see that there are numerous tidy and quality issues with the data. We have NaN values, None values, the strings in `source` need to be cleaned up, ect. \n",
    "\n",
    "Next, I will use the twitter API to access the JSON of each tweet. I will use each ID from the `tweet_id` column in `df_twitter`, save the JSON to a text file, then use that text file to find more data on each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oauth authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret, callback_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    redirect_url = auth.get_authorization_url()\n",
    "except tweepy.TweepError:\n",
    "    print('Error! Failed to get request token.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the api using the tweepy library\n",
    "api = tweepy.API(auth, \n",
    "                 parser = tweepy.parsers.JSONParser(),\n",
    "                 wait_on_rate_limit = True,\n",
    "                 wait_on_rate_limit_notify = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I wrote a script that loops through the `tweet_id` column and uses each ID to access the tweet JSON. I then store all of the json in a list, which then gets outputed to a text file at the end of the script. While the loops is running, it catches errors and stores the ID in a list called `tweet_errors`. Also, the script will print out any ID that his has errors with. It's nice to be able to track what your script is doing when it runs for such a long time. When you access the twitter API too much, you reach your rate limit. Once this happens, the script gets \"put to sleep\" for 15 to 30 minutes. This was one of the biggest challenges of this project. Since it takes roughly an hour for this script to run, it needed to be tested on a much smaller scale so there are zero errors when used on the dataset.\n",
    "\n",
    "While writing this script, I stumbled upon a very useful technique for gathering data. This method comes from the `collections` library. I imported a method called `defaultdict`. Essentially it makes a basic python dictionary, but with something a little extra. If the key in the dictionary is not present, it will put a new key with it's value in the dictionary. Once you need to add another value to the same key, it will add the value to the same key as a list. So no matter what, you will create a dictionary that you can later turn into a dataframe with a few lines of code.\n",
    "\n",
    "Once the JSON is dumped and the dictionary is turned into a dataframe, the dataframe is then turned into a csv file for later cleaning and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in extracting 888202515573088257\n",
      "error in extracting 873697596434513921\n",
      "error in extracting 869988702071779329\n",
      "error in extracting 866816280283807744\n",
      "error in extracting 861769973181624320\n",
      "error in extracting 845459076796616705\n",
      "error in extracting 842892208864923648\n",
      "error in extracting 837012587749474308\n",
      "error in extracting 827228250799742977\n",
      "error in extracting 802247111496568832\n",
      "error in extracting 775096608509886464\n",
      "error in extracting 771004394259247104\n",
      "error in extracting 770743923962707968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in extracting 754011816964026368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script took 1618.222422361374 seconds to run\n",
      "There were 14 tweet errors when the script was ran\n"
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "start_time = time.time()\n",
    "# list of tweet json\n",
    "tweet_json = []\n",
    "# dictionary of extracted tweet data\n",
    "tweet_dict = defaultdict(list)\n",
    "# errors (if any) of tweet extraction\n",
    "tweet_errors = []\n",
    "\n",
    "for tweet_id in df_twitter.tweet_id:\n",
    "    try:\n",
    "        # get tweet\n",
    "        tweet = api.get_status(tweet_id, tweet_mode = 'extended')\n",
    "        # append json to tweet_json list\n",
    "        tweet_json.append(tweet)\n",
    "        # extract tweet data\n",
    "        tweet_dict['retweet_count'].append(tweet['retweet_count'])\n",
    "        tweet_dict['favorite_count'].append(tweet['favorite_count'])\n",
    "        tweet_dict['tweet_id'].append(tweet['id'])   \n",
    "    except:\n",
    "        # if tweet is not extracted, append id to tweet_errors\n",
    "        tweet_errors.append(tweet_id)\n",
    "        # print id with error\n",
    "        print('error in extracting' + ' ' + str(tweet_id))\n",
    "# dump json into txt file\n",
    "with open('tweet_json.txt', 'w', encoding = 'utf8') as tweettxtfile:\n",
    "    json.dump(tweet_json, tweettxtfile, sort_keys = True, indent = 4, ensure_ascii = False)\n",
    "# dict to dataframe\n",
    "df_twitter_extract = pd.DataFrame.from_dict(tweet_dict)\n",
    "# dataframe to csv\n",
    "df_twitter_extract.to_csv('df_twitter_extract.csv', encoding='utf-8')\n",
    "print('Script took %s seconds to run' % (time.time() - start_time))\n",
    "error_length = len(tweet_errors)\n",
    "print('There were %s tweet errors when the script was ran' % error_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, there were only 14 errors when the script was ran. After checking the `tweet_json.txt`, there are a total of 461,441 lines of JSON. For the file I used the `sort_keys`, `indent`, and `ensure_ascii` to make a clean and readable json file. This helped later on when I needed to view a twitter object in the JSON file to figure out what code I needed to access certain elements.\n",
    "\n",
    "For the next part, I wanted to add some extra data to the project. I wanted to extract the JSON of the user's who were getting tagged in certain tweets on WeRateDogs. Using the ID's from `twitter_df`, I accessed the url's of the tweets with the `BeautifulSoup` library. Then, I saved the html of each url in a folder for later use. I named each file by splitting the string of the url and adding the ID to the file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "html_tweet_dict = defaultdict(list)\n",
    "\n",
    "html_tweet_errors = []\n",
    "for tweet_id in df_twitter.tweet_id:\n",
    "    try:\n",
    "        url = api.get_status(tweet_id)['entities']['urls'][0]['expanded_url']\n",
    "        r = requests.get(url)\n",
    "        html_tweet_dict['link'].append(url)\n",
    "        html_tweet_dict['tweet_id'].append(tweet_id)\n",
    "        # access html with BeautifulSoup\n",
    "        soup = BeautifulSoup(r.text, 'html.parser').prettify()\n",
    "        # save html of tweet to tweet_html folder\n",
    "        with open('tweet_html/html_' + url.split('/')[-1] + '.html', 'w', encoding = 'utf-8') as file:\n",
    "            file.write(str(soup))\n",
    "    except:\n",
    "        html_tweet_errors.append(tweet_id)\n",
    "        print('error in obtaining url from tweet ID %s' % tweet_id)\n",
    "\n",
    "# turn dict into dataframe\n",
    "df_html_extract = pd.DataFrame.from_dict(html_tweet_dict)\n",
    "# dataframe to csv\n",
    "df_html_extract.to_csv('df_html_extract.csv', encoding='utf-8')\n",
    "\n",
    "print('Script took %s seconds to run' % (time.time() - start_time))\n",
    "html_error_length = len(html_tweet_errors)\n",
    "print('There were %s user tweet errors when the script was ran' % html_error_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1973"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(html_tweet_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this script, there were a total of 1973 errors. The cause of the errors was the `url` variable in the loop. Due to some tweets being a bit old, the JSON of those tweets were different than others. So to narrow down the number of errors. I searched for another way to grab the url from the JSON and ran the script again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "html_tweet_errors_2 = []\n",
    "\n",
    "# loop through html_tweet_errors\n",
    "for tweet_id in html_tweet_errors:\n",
    "    try:\n",
    "        # changed strings to access correct link\n",
    "        url = api.get_status(tweet_id)['entities']['media'][0]['expanded_url']\n",
    "        r = requests.get(url)\n",
    "        html_tweet_dict['link'].append(url)\n",
    "        html_tweet_dict['tweet_id'].append(tweet_id)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser').prettify()\n",
    "        # save html of tweet to tweet_html folder (changed index to -3)\n",
    "        with open('tweet_html/html_' + url.split('/')[-3] + '.html', 'w', encoding = 'utf-8') as file:\n",
    "            file.write(str(soup))\n",
    "    except:\n",
    "        html_tweet_errors_2.append(tweet_id)\n",
    "        print('error in obtaining url from tweet ID %s' % tweet_id)\n",
    "\n",
    "df_html_extract_2 = pd.DataFrame.from_dict(html_tweet_dict)\n",
    "# dataframe to csv\n",
    "df_html_extract_2.to_csv('df_html_extract_.csv', encoding='utf-8')\n",
    "\n",
    "print('Script took %s seconds to run' % (time.time() - start_time))\n",
    "html_error_length_2 = len(html_tweet_errors_2)\n",
    "print('There were %s user tweet errors when the script was ran' % html_error_length_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(html_tweet_errors_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I narrowed it down to 153 errors. AFter some digging, most of the other 153 ID's url's didn't exist on twitter anymore, so I decided to move on.\n",
    "\n",
    "With those two scripts ran, I now have the HTML for most of the tweets. I also have a CSV file called `df_html_extract` that has the ID and the url of that ID. This will be used later to add missing data to the `df_twitter` dataframe.\n",
    "\n",
    "Next, I will use the HTML files extracted earlier and find the user ID of the profile tagged in the original tweet. After inspecting the link of the tagged user on twitter, I discovered that there was a `div` with a class called `media-tagging-block` that had a number in `data-user-id`. With this ID number, we can use `api.get_user` to extract the json just as we did with the original tweets.\n",
    "\n",
    "So for the script I wrote below, it will loop through the html files, find the user ID number, extract the JSON of the user, and collect data from it. After all of the data is collected it puts it in a csv file called `df_user_extract`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of user tweet json\n",
    "user_tweet_json = []\n",
    "# tweet data of users tagged in original tweet\n",
    "user_tweet_dict = defaultdict(list)\n",
    "# list of errors\n",
    "user_tweet_error = []\n",
    "folder = 'tweet_html'\n",
    "for tweet_html in os.listdir(folder):\n",
    "    try:\n",
    "        with open(os.path.join(folder, tweet_html), encoding = 'utf-8') as file:\n",
    "            soup = BeautifulSoup(file, 'html.parser')\n",
    "            # find user ID of profile tagged in original tweet\n",
    "            user_id = soup.find('div', 'media-tagging-block')('a')[0].get('data-user-id')\n",
    "            # get profile JSON using user ID\n",
    "            user_json = api.get_user(user_id)\n",
    "            # put json in user_tweet_json\n",
    "            user_tweet_json.append(user_json)\n",
    "            # extract user profile data\n",
    "            user_tweet_dict['created_at'].append(user_json['created_at'])\n",
    "            user_tweet_dict['friends_count'].append(user_json['friends_count'])\n",
    "            user_tweet_dict['user_id'].append(user_json['id_str'])\n",
    "            user_tweet_dict['language'].append(user_json['lang'])\n",
    "            user_tweet_dict['location'].append(user_json['location'])\n",
    "            user_tweet_dict['display_name'].append(user_json['name'])\n",
    "            user_tweet_dict['account_name'].append(user_json['screen_name'])\n",
    "    except:\n",
    "        user_tweet_error.append(file)\n",
    "        print('error in obtaining tagged user ID data from %s' % file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('user_tweet_json.txt', 'w', encoding = 'utf-8') as usertxtfile:\n",
    "    json.dump(user_tweet_json, usertxtfile, sort_keys = True, indent = 4, ensure_ascii = False)\n",
    "df_user_extract = pd.DataFrame.from_dict(user_tweet_dict)\n",
    "# dataframe to csv\n",
    "df_user_extract.to_csv('df_user_extract.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1412"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_tweet_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "With this script I was able to extract user data for 718 individuals. There were 1412 errors mostly because not all tweets had a tagged user in it. The data I was able to collect included the date in which the user joined twitter, friends count, user ID, language spoken, location of user, display name, and account name.\n",
    "\n",
    "In summary, I collected the twitter archive of WeRateDogs, the HTMl of each tweet link, tagged user data, image predictions from Udacity's servers, and JSON for tagged users and for each tweet in the archive. The next step will be to clean and organize the data, so we have good quality and tidiness for analyzation. \n",
    "\n",
    "# Cleaning\n",
    "\n",
    "To start out, lets take a look at each csv file we gathered to see what data we have to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 16:23:56 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892420643...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Phineas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 00:17:27 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Tilly. She's just checking pup on you....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892177421...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Tilly</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>891815181378084864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-31 00:18:03 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891815181...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Archie</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>891689557279858688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-30 15:58:51 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Darla. She commenced a snooze mid meal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891689557...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Darla</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>891327558926688256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-29 16:00:24 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Franklin. He would like you to stop ca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891327558...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "0  892420643555336193                    NaN                  NaN   \n",
       "1  892177421306343426                    NaN                  NaN   \n",
       "2  891815181378084864                    NaN                  NaN   \n",
       "3  891689557279858688                    NaN                  NaN   \n",
       "4  891327558926688256                    NaN                  NaN   \n",
       "\n",
       "                   timestamp  \\\n",
       "0  2017-08-01 16:23:56 +0000   \n",
       "1  2017-08-01 00:17:27 +0000   \n",
       "2  2017-07-31 00:18:03 +0000   \n",
       "3  2017-07-30 15:58:51 +0000   \n",
       "4  2017-07-29 16:00:24 +0000   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text  retweeted_status_id  \\\n",
       "0  This is Phineas. He's a mystical boy. Only eve...                  NaN   \n",
       "1  This is Tilly. She's just checking pup on you....                  NaN   \n",
       "2  This is Archie. He is a rare Norwegian Pouncin...                  NaN   \n",
       "3  This is Darla. She commenced a snooze mid meal...                  NaN   \n",
       "4  This is Franklin. He would like you to stop ca...                  NaN   \n",
       "\n",
       "   retweeted_status_user_id retweeted_status_timestamp  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "2                       NaN                        NaN   \n",
       "3                       NaN                        NaN   \n",
       "4                       NaN                        NaN   \n",
       "\n",
       "                                       expanded_urls  rating_numerator  \\\n",
       "0  https://twitter.com/dog_rates/status/892420643...                13   \n",
       "1  https://twitter.com/dog_rates/status/892177421...                13   \n",
       "2  https://twitter.com/dog_rates/status/891815181...                12   \n",
       "3  https://twitter.com/dog_rates/status/891689557...                13   \n",
       "4  https://twitter.com/dog_rates/status/891327558...                12   \n",
       "\n",
       "   rating_denominator      name doggo floofer pupper puppo  \n",
       "0                  10   Phineas  None    None   None  None  \n",
       "1                  10     Tilly  None    None   None  None  \n",
       "2                  10    Archie  None    None   None  None  \n",
       "3                  10     Darla  None    None   None  None  \n",
       "4                  10  Franklin  None    None   None  None  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a copy of df_twitter to alter it later\n",
    "df_twitter_copy = df_twitter.copy()\n",
    "df_twitter_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>666020888022790149</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Welsh_springer_spaniel</td>\n",
       "      <td>0.465074</td>\n",
       "      <td>True</td>\n",
       "      <td>collie</td>\n",
       "      <td>0.156665</td>\n",
       "      <td>True</td>\n",
       "      <td>Shetland_sheepdog</td>\n",
       "      <td>0.061428</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>666029285002620928</td>\n",
       "      <td>https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.506826</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.074192</td>\n",
       "      <td>True</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.072010</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>666033412701032449</td>\n",
       "      <td>https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>German_shepherd</td>\n",
       "      <td>0.596461</td>\n",
       "      <td>True</td>\n",
       "      <td>malinois</td>\n",
       "      <td>0.138584</td>\n",
       "      <td>True</td>\n",
       "      <td>bloodhound</td>\n",
       "      <td>0.116197</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>666044226329800704</td>\n",
       "      <td>https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>0.408143</td>\n",
       "      <td>True</td>\n",
       "      <td>redbone</td>\n",
       "      <td>0.360687</td>\n",
       "      <td>True</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.222752</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>666049248165822465</td>\n",
       "      <td>https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>miniature_pinscher</td>\n",
       "      <td>0.560311</td>\n",
       "      <td>True</td>\n",
       "      <td>Rottweiler</td>\n",
       "      <td>0.243682</td>\n",
       "      <td>True</td>\n",
       "      <td>Doberman</td>\n",
       "      <td>0.154629</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                          jpg_url  \\\n",
       "0  666020888022790149  https://pbs.twimg.com/media/CT4udn0WwAA0aMy.jpg   \n",
       "1  666029285002620928  https://pbs.twimg.com/media/CT42GRgUYAA5iDo.jpg   \n",
       "2  666033412701032449  https://pbs.twimg.com/media/CT4521TWwAEvMyu.jpg   \n",
       "3  666044226329800704  https://pbs.twimg.com/media/CT5Dr8HUEAA-lEu.jpg   \n",
       "4  666049248165822465  https://pbs.twimg.com/media/CT5IQmsXIAAKY4A.jpg   \n",
       "\n",
       "   img_num                      p1   p1_conf  p1_dog                  p2  \\\n",
       "0        1  Welsh_springer_spaniel  0.465074    True              collie   \n",
       "1        1                 redbone  0.506826    True  miniature_pinscher   \n",
       "2        1         German_shepherd  0.596461    True            malinois   \n",
       "3        1     Rhodesian_ridgeback  0.408143    True             redbone   \n",
       "4        1      miniature_pinscher  0.560311    True          Rottweiler   \n",
       "\n",
       "    p2_conf  p2_dog                   p3   p3_conf  p3_dog  \n",
       "0  0.156665    True    Shetland_sheepdog  0.061428    True  \n",
       "1  0.074192    True  Rhodesian_ridgeback  0.072010    True  \n",
       "2  0.138584    True           bloodhound  0.116197    True  \n",
       "3  0.360687    True   miniature_pinscher  0.222752    True  \n",
       "4  0.243682    True             Doberman  0.154629    True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_predictions = pd.read_csv('image-predictions.tsv', sep = '\\t')\n",
    "image_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>link</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/i/web/status/8921774213063...</td>\n",
       "      <td>892177421306343426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://twitter.com/i/web/status/8918151813780...</td>\n",
       "      <td>891815181378084864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://twitter.com/i/web/status/8913275589266...</td>\n",
       "      <td>891327558926688256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://twitter.com/i/web/status/8910879508758...</td>\n",
       "      <td>891087950875897856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://twitter.com/i/web/status/8909719131739...</td>\n",
       "      <td>890971913173991426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               link  \\\n",
       "0           0  https://twitter.com/i/web/status/8921774213063...   \n",
       "1           1  https://twitter.com/i/web/status/8918151813780...   \n",
       "2           2  https://twitter.com/i/web/status/8913275589266...   \n",
       "3           3  https://twitter.com/i/web/status/8910879508758...   \n",
       "4           4  https://twitter.com/i/web/status/8909719131739...   \n",
       "\n",
       "             tweet_id  \n",
       "0  892177421306343426  \n",
       "1  891815181378084864  \n",
       "2  891327558926688256  \n",
       "3  891087950875897856  \n",
       "4  890971913173991426  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_html_extract = pd.read_csv('df_html_extract.csv')\n",
    "df_html_extract.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>38489</td>\n",
       "      <td>8472</td>\n",
       "      <td>892420643555336193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32964</td>\n",
       "      <td>6237</td>\n",
       "      <td>892177421306343426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>24829</td>\n",
       "      <td>4133</td>\n",
       "      <td>891815181378084864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>41857</td>\n",
       "      <td>8597</td>\n",
       "      <td>891689557279858688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>40017</td>\n",
       "      <td>9327</td>\n",
       "      <td>891327558926688256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  favorite_count  retweet_count            tweet_id\n",
       "0           0           38489           8472  892420643555336193\n",
       "1           1           32964           6237  892177421306343426\n",
       "2           2           24829           4133  891815181378084864\n",
       "3           3           41857           8597  891689557279858688\n",
       "4           4           40017           9327  891327558926688256"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra data extracted for twitter archive\n",
    "df_twitter_extract = pd.read_csv('df_twitter_extract.csv')\n",
    "df_twitter_extract.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>account_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>display_name</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>language</th>\n",
       "      <th>location</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dog_rates</td>\n",
       "      <td>Sun Nov 15 21:41:29 +0000 2015</td>\n",
       "      <td>WeRateDogs™</td>\n",
       "      <td>10</td>\n",
       "      <td>en</td>\n",
       "      <td>⇩ merch ⇩         DM YOUR DOGS</td>\n",
       "      <td>4196983835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tta_kay</td>\n",
       "      <td>Sat Jul 05 17:06:22 +0000 2014</td>\n",
       "      <td>kay</td>\n",
       "      <td>479</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2676442024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Adeline_Garrett</td>\n",
       "      <td>Fri Apr 26 16:34:47 +0000 2013</td>\n",
       "      <td>outofline carrot 🦊</td>\n",
       "      <td>415</td>\n",
       "      <td>en</td>\n",
       "      <td>912•LDN</td>\n",
       "      <td>1382344291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>gwatsky</td>\n",
       "      <td>Sun Jan 10 03:38:19 +0000 2010</td>\n",
       "      <td>W▵TSKY</td>\n",
       "      <td>865</td>\n",
       "      <td>en</td>\n",
       "      <td>yeah</td>\n",
       "      <td>103467620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SmilingYoshi</td>\n",
       "      <td>Sun Jun 12 20:38:49 +0000 2011</td>\n",
       "      <td>SmilingYoshi</td>\n",
       "      <td>1412</td>\n",
       "      <td>en</td>\n",
       "      <td>Here.</td>\n",
       "      <td>316025613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     account_name                      created_at  \\\n",
       "0           0        dog_rates  Sun Nov 15 21:41:29 +0000 2015   \n",
       "1           1          tta_kay  Sat Jul 05 17:06:22 +0000 2014   \n",
       "2           2  Adeline_Garrett  Fri Apr 26 16:34:47 +0000 2013   \n",
       "3           3          gwatsky  Sun Jan 10 03:38:19 +0000 2010   \n",
       "4           4     SmilingYoshi  Sun Jun 12 20:38:49 +0000 2011   \n",
       "\n",
       "         display_name  friends_count language                        location  \\\n",
       "0         WeRateDogs™             10       en  ⇩ merch ⇩         DM YOUR DOGS   \n",
       "1                 kay            479       en                             NaN   \n",
       "2  outofline carrot 🦊            415       en                         912•LDN   \n",
       "3              W▵TSKY            865       en                            yeah   \n",
       "4        SmilingYoshi           1412       en                           Here.   \n",
       "\n",
       "      user_id  \n",
       "0  4196983835  \n",
       "1  2676442024  \n",
       "2  1382344291  \n",
       "3   103467620  \n",
       "4   316025613  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_extract = pd.read_csv('df_user_extract.csv')\n",
    "df_user_extract.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only data frame that I will be changing and adding data too is `df_twitter`. Mainly because all of my other tables (except `df_user_extract`) have the `tweet_id`'s in each. One method you will see throughout this cleaning process is `map`. Conveniently, I can use the tweet ID's from my extracted data and map it to the twitter archive data. That way, we have the data next to the associated tweet ID.\n",
    "\n",
    "After doing a visual analysis on the `df_twitter` table, I listed some quality and tidiness issues that need to be fixed:\n",
    "\n",
    "### Quality Issues\n",
    "* Change `tweet_id` column to a `string`\n",
    "* Change `timestamp` to `datetime`\n",
    "* Extract the text in each row for the `source column` with beautiful soup\n",
    "* Change `doggo`, `floofer`, `pupper`, and `puppo` to boolean\n",
    "* drop `expanded_urls` column, extract urls with tweet id's, then map urls to `df_twitter`\n",
    "* Extract `retweeted` element from each object in `tweet_json` and map column to `df_twitter`\n",
    "* Create a column that divides the numerator to the denominator to have a common rating system\n",
    "* Fix any outliers in the `name` column, for example, \"a\" as a name\n",
    "\n",
    "### Tidiness Issues\n",
    "* remove the following rows: `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id`, `retweeted_status_timestamp`\n",
    "* after above step, remove rows that have missing data\n",
    "\n",
    "### Misc.\n",
    "* Extract image link, first confidence level, and breed of dogs that are `True` breeds from `image_predictions`\n",
    "\n",
    "First I will start off by mapping the extra tweet archive data to `df_twitter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map df_twitter_extract to df_twitter\n",
    "df_twitter_copy['retweet_count'] = df_twitter_copy['tweet_id'].map(df_twitter_extract.set_index('tweet_id')['retweet_count'])\n",
    "df_twitter_copy['favorite_count'] = df_twitter_copy['tweet_id'].map(df_twitter_extract.set_index('tweet_id')['favorite_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I extracted the `retweeted` status of each tweet and added it to the `df_twitter` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "retweet_status_dict = defaultdict(list)\n",
    "json_file = 'tweet_json.txt'\n",
    "with open(json_file, encoding = 'utf-8') as f:\n",
    "    data = json.load(f)\n",
    "    for element in data:\n",
    "        retweet_status_dict['retweeted'].append(element['retweeted'])\n",
    "        retweet_status_dict['tweet_id'].append(element['id'])\n",
    "    print('done!')\n",
    "df_retweet_status = pd.DataFrame.from_dict(retweet_status_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweeted</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>892420643555336193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>892177421306343426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>891815181378084864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>891689557279858688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>891327558926688256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   retweeted            tweet_id\n",
       "0      False  892420643555336193\n",
       "1      False  892177421306343426\n",
       "2      False  891815181378084864\n",
       "3      False  891689557279858688\n",
       "4      False  891327558926688256"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_retweet_status.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add retweeted column to df_twitter\n",
    "df_twitter_copy['retweeted'] = df_twitter_copy['tweet_id'].map(df_retweet_status.set_index('tweet_id')['retweeted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 20 columns):\n",
      "tweet_id                      2356 non-null int64\n",
      "in_reply_to_status_id         78 non-null float64\n",
      "in_reply_to_user_id           78 non-null float64\n",
      "timestamp                     2356 non-null object\n",
      "source                        2356 non-null object\n",
      "text                          2356 non-null object\n",
      "retweeted_status_id           181 non-null float64\n",
      "retweeted_status_user_id      181 non-null float64\n",
      "retweeted_status_timestamp    181 non-null object\n",
      "expanded_urls                 2297 non-null object\n",
      "rating_numerator              2356 non-null int64\n",
      "rating_denominator            2356 non-null int64\n",
      "name                          2356 non-null object\n",
      "doggo                         2356 non-null object\n",
      "floofer                       2356 non-null object\n",
      "pupper                        2356 non-null object\n",
      "puppo                         2356 non-null object\n",
      "retweet_count                 2342 non-null float64\n",
      "favorite_count                2342 non-null float64\n",
      "retweeted                     2342 non-null object\n",
      "dtypes: float64(6), int64(3), object(11)\n",
      "memory usage: 368.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_twitter_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the structure of `df_twitter_copy`, we see that there are a great number of missing values, and data types that should not be there. I decided that the columns `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id`, and `retweeted_status_timestamp` were not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "df_twitter_copy = df_twitter_copy.drop(['in_reply_to_status_id', 'in_reply_to_user_id', 'retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the column `expanded_urls`, there were a great number of values that were \"None\", to fix this, I used the urls that I extracted earlier in the `df_html_extract` table, and mapped it to `df_twitter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop original expanded_urls column\n",
    "df_twitter_copy = df_twitter_copy.drop('expanded_urls', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map urls to df_twitter\n",
    "df_twitter_copy['expanded_urls'] = df_twitter_copy['tweet_id'].map(df_html_extract.drop_duplicates('tweet_id').set_index('tweet_id')['link'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next steps, I will turn the `tweet_id` column in to a string type, and `timestamp` into DateTime type. Since the ID numbers do not need to be calculated in any mathematical way and shouldn't be changed, they should be strings. The DateTime type for the `timestamp` column will be usefull for visualization when I need to put elements in order by time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn tweet_id into string type\n",
    "df_twitter_copy['tweet_id'] = df_twitter_copy['tweet_id'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn timestamp into DateTime\n",
    "df_twitter_copy['timestamp'] = pd.to_datetime(df_twitter_copy['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this next section I used BeautifulSoup to extract the content in each html tag for the `source` column. BeauifulSoup was the easiest method to use for parsing the html string. Once I was able to extract the content of each tag, I then used the `replace` method to change the source types into simple strings such as iphone, vine, web, and tweetdeck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for accessing tag content\n",
    "def source_text(html):\n",
    "    source = BeautifulSoup(html, 'lxml')\n",
    "    return source.a.string\n",
    "\n",
    "# change each cell to tag content with lambda function\n",
    "df_twitter_copy['source_text'] = df_twitter_copy.apply(lambda row: source_text(row['source']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop original source column\n",
    "df_twitter_copy.drop('source', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of string replacements\n",
    "replacements = {\n",
    "    'Twitter for iPhone': 'iphone',\n",
    "    'Vine - Make a Scene': 'vine',\n",
    "    'Twitter Web Client': 'web',\n",
    "    'TweetDeck': 'tweetdeck'\n",
    "}\n",
    "\n",
    "# apply replacements\n",
    "df_twitter_copy['source_text'].replace(replacements, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I used the same method as above for replacing values in the `doggo`, `floofer`, `pupper`, and `puppo` columns. In the original `df_twitter` table, each column either had the label \"None\" or the given category of the dog, \"doggo\" for example. So for each value, if there was a category name, it was switched to `True`, and for each \"None\" value, it was switched to `False`. These boolean values will allow me to easily analyze each column, `df_twitter.doggo.mean()` for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to be changed\n",
    "cols = ['doggo', 'floofer', 'pupper', 'puppo']\n",
    "\n",
    "\n",
    "replacements_dog = {\n",
    "    'doggo': True,\n",
    "    'floofer': True,\n",
    "    'pupper': True,\n",
    "    'puppo': True,\n",
    "    'None': False\n",
    "}\n",
    "\n",
    "df_twitter_copy[cols] = df_twitter_copy[cols].replace(replacements_dog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to make sure there are no missing values in the dataset. Since we have collected everything we will need, we will not need rows that have missing data, as we were not able to collect data for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop any rows that have NaN values\n",
    "df_twitter_copy = df_twitter_copy.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the scores in this data vary in scale (14/10 , 150/164, for example) the best way to have a consistent score in the entire data set is to divide the numerator by the denominator. This will allow us to easily make visualizations that show us average score, scores over time, highest score, ect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide numerator column by denominator column\n",
    "df_twitter_copy['score_rating'] = df_twitter_copy.rating_numerator / df_twitter_copy.rating_denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same `replace` method, we can change certain outliers in the `name` column. \"a\" is clearly not a name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements_name = {\n",
    "    'a': 'None',\n",
    "    'the': 'None',\n",
    "    'an': 'None',\n",
    "    'officially': 'None',\n",
    "    'O': \"O'Malley\"\n",
    "}\n",
    "\n",
    "df_twitter_copy['name'].replace(replacements_name, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next steps, I will focus on joining the `image_predictions` data with `df_twitter`. I will narrow the image predictions table down to only rows where `p1_dog` are `True`. We only want strings in the column that are actual dogs that exist. Along with the name of the breed, I'll also include the JPEG file of the dog, and the confidence level in which the algorithm calculated. Since the image predictions table get's narrowed down to about 500 less datapoints then the twitter archive, I'll have to fill in the missing data with either a string \"None\", or a zero for integer columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy\n",
    "image_predictions_copy = image_predictions.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows where p1_dog is False\n",
    "image_predictions_copy.drop(image_predictions_copy[image_predictions_copy.p1_dog == False].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all other unneeded rows\n",
    "image_predictions_copy = image_predictions_copy.drop(['img_num', 'p2', 'p2_conf', 'p2_dog', 'p3', 'p3_conf', 'p3_dog'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index \n",
    "image_predictions_copy = image_predictions_copy.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make each tweet_id column identical for mapping\n",
    "image_predictions_copy['tweet_id'] = image_predictions_copy['tweet_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map data to the twitter archive\n",
    "df_twitter_copy['jpg_url'] = df_twitter_copy['tweet_id'].map(image_predictions_copy.set_index('tweet_id')['jpg_url'])\n",
    "df_twitter_copy['p1'] = df_twitter_copy['tweet_id'].map(image_predictions_copy.set_index('tweet_id')['p1'])\n",
    "df_twitter_copy['p1_conf'] = df_twitter_copy['tweet_id'].map(image_predictions_copy.set_index('tweet_id')['p1_conf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in NaN values\n",
    "df_twitter_copy[['jpg_url', 'p1']] = df_twitter_copy[['jpg_url', 'p1']].fillna('None')\n",
    "df_twitter_copy['p1_conf'] = df_twitter_copy['p1_conf'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>source_text</th>\n",
       "      <th>score_rating</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>2017-08-01 16:23:56</td>\n",
       "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Phineas</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8472.0</td>\n",
       "      <td>38489.0</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892420643...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>1.3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>2017-08-01 00:17:27</td>\n",
       "      <td>This is Tilly. She's just checking pup on you....</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Tilly</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6237.0</td>\n",
       "      <td>32964.0</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/i/web/status/8921774213063...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>1.3</td>\n",
       "      <td>https://pbs.twimg.com/media/DGGmoV4XsAAUL6n.jpg</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>0.323581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>891815181378084864</td>\n",
       "      <td>2017-07-31 00:18:03</td>\n",
       "      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Archie</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4133.0</td>\n",
       "      <td>24829.0</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/i/web/status/8918151813780...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>1.2</td>\n",
       "      <td>https://pbs.twimg.com/media/DGBdLU1WsAANxJ9.jpg</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>0.716012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>891689557279858688</td>\n",
       "      <td>2017-07-30 15:58:51</td>\n",
       "      <td>This is Darla. She commenced a snooze mid meal...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Darla</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8597.0</td>\n",
       "      <td>41857.0</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891689557...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>1.3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>891327558926688256</td>\n",
       "      <td>2017-07-29 16:00:24</td>\n",
       "      <td>This is Franklin. He would like you to stop ca...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>9327.0</td>\n",
       "      <td>40017.0</td>\n",
       "      <td>False</td>\n",
       "      <td>https://twitter.com/i/web/status/8913275589266...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>1.2</td>\n",
       "      <td>https://pbs.twimg.com/media/DF6hr6BUMAAzZgT.jpg</td>\n",
       "      <td>basset</td>\n",
       "      <td>0.555712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id           timestamp  \\\n",
       "0  892420643555336193 2017-08-01 16:23:56   \n",
       "1  892177421306343426 2017-08-01 00:17:27   \n",
       "2  891815181378084864 2017-07-31 00:18:03   \n",
       "3  891689557279858688 2017-07-30 15:58:51   \n",
       "4  891327558926688256 2017-07-29 16:00:24   \n",
       "\n",
       "                                                text  rating_numerator  \\\n",
       "0  This is Phineas. He's a mystical boy. Only eve...                13   \n",
       "1  This is Tilly. She's just checking pup on you....                13   \n",
       "2  This is Archie. He is a rare Norwegian Pouncin...                12   \n",
       "3  This is Darla. She commenced a snooze mid meal...                13   \n",
       "4  This is Franklin. He would like you to stop ca...                12   \n",
       "\n",
       "   rating_denominator      name  doggo  floofer  pupper  puppo  retweet_count  \\\n",
       "0                  10   Phineas  False    False   False  False         8472.0   \n",
       "1                  10     Tilly  False    False   False  False         6237.0   \n",
       "2                  10    Archie  False    False   False  False         4133.0   \n",
       "3                  10     Darla  False    False   False  False         8597.0   \n",
       "4                  10  Franklin  False    False   False  False         9327.0   \n",
       "\n",
       "   favorite_count retweeted  \\\n",
       "0         38489.0     False   \n",
       "1         32964.0     False   \n",
       "2         24829.0     False   \n",
       "3         41857.0     False   \n",
       "4         40017.0     False   \n",
       "\n",
       "                                       expanded_urls source_text  \\\n",
       "0  https://twitter.com/dog_rates/status/892420643...      iphone   \n",
       "1  https://twitter.com/i/web/status/8921774213063...      iphone   \n",
       "2  https://twitter.com/i/web/status/8918151813780...      iphone   \n",
       "3  https://twitter.com/dog_rates/status/891689557...      iphone   \n",
       "4  https://twitter.com/i/web/status/8913275589266...      iphone   \n",
       "\n",
       "   score_rating                                          jpg_url         p1  \\\n",
       "0           1.3                                             None       None   \n",
       "1           1.3  https://pbs.twimg.com/media/DGGmoV4XsAAUL6n.jpg  Chihuahua   \n",
       "2           1.2  https://pbs.twimg.com/media/DGBdLU1WsAANxJ9.jpg  Chihuahua   \n",
       "3           1.3                                             None       None   \n",
       "4           1.2  https://pbs.twimg.com/media/DF6hr6BUMAAzZgT.jpg     basset   \n",
       "\n",
       "    p1_conf  \n",
       "0  0.000000  \n",
       "1  0.323581  \n",
       "2  0.716012  \n",
       "3  0.000000  \n",
       "4  0.555712  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2206 entries, 0 to 2355\n",
      "Data columns (total 19 columns):\n",
      "tweet_id              2206 non-null object\n",
      "timestamp             2206 non-null datetime64[ns]\n",
      "text                  2206 non-null object\n",
      "rating_numerator      2206 non-null int64\n",
      "rating_denominator    2206 non-null int64\n",
      "name                  2206 non-null object\n",
      "doggo                 2206 non-null bool\n",
      "floofer               2206 non-null bool\n",
      "pupper                2206 non-null bool\n",
      "puppo                 2206 non-null bool\n",
      "retweet_count         2206 non-null float64\n",
      "favorite_count        2206 non-null float64\n",
      "retweeted             2206 non-null object\n",
      "expanded_urls         2206 non-null object\n",
      "source_text           2206 non-null object\n",
      "score_rating          2206 non-null float64\n",
      "jpg_url               2206 non-null object\n",
      "p1                    2206 non-null object\n",
      "p1_conf               2206 non-null float64\n",
      "dtypes: bool(4), datetime64[ns](1), float64(4), int64(2), object(8)\n",
      "memory usage: 284.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_twitter_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, I will do some quick cleaning on the `df_user_extract` dataframe. Let's see what we need to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 718 entries, 0 to 717\n",
      "Data columns (total 8 columns):\n",
      "Unnamed: 0       718 non-null int64\n",
      "account_name     718 non-null object\n",
      "created_at       718 non-null object\n",
      "display_name     718 non-null object\n",
      "friends_count    718 non-null int64\n",
      "language         718 non-null object\n",
      "location         457 non-null object\n",
      "user_id          718 non-null int64\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 45.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_user_extract.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality\n",
    "* make user_id a string column type\n",
    "* fill in NaN values for location with \"not given\"\n",
    "\n",
    "### Tidiness\n",
    "* remove unnamed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_extract['user_id'] = df_user_extract['user_id'].astype(str)\n",
    "df_user_extract = df_user_extract.drop('Unnamed: 0', axis = 1)\n",
    "df_user_extract['location'] = df_user_extract['location'].fillna(\"not given\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 718 entries, 0 to 717\n",
      "Data columns (total 7 columns):\n",
      "account_name     718 non-null object\n",
      "created_at       718 non-null object\n",
      "display_name     718 non-null object\n",
      "friends_count    718 non-null int64\n",
      "language         718 non-null object\n",
      "location         718 non-null object\n",
      "user_id          718 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 39.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_user_extract.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have two clean and tidy datasets to work with, lets export them each to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_copy.to_csv('twitter_archive_master.csv', index = False, encoding='utf-8')\n",
    "df_user_extract.to_csv('user_extract_master.csv', index = False, encoding = 'utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
